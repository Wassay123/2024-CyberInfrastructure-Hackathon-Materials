{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sample Tutorial: Testing your Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello teams! In order to help streamline the judging process for each of your models, this notebook will walk through how to format your models for easy and fair evaluation.\n",
    "\n",
    "This sample tutorial will be using the previous sample LSTM model given in the training notebook to show how models will be tested. We hope this transparency will allow for teams to understand exactly how models will be judged. \n",
    "\n",
    "Let's first begin by importing some basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the first week of our original training dataset for testing. Let's go ahead and open and access that data now\n",
    "\n",
    "Note: this will not be the actual dataset being used the for final model judging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('datasets/training_data.h5', 'r') as f:\n",
    "    # Access the trip dataset and their corresponding timestamps\n",
    "    traffic_data = f['trip'][()]\n",
    "    dates = f['timeslot'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_size = 48 * 7\n",
    "\n",
    "test_traffic_data = traffic_data[:test_set_size]\n",
    "test_dates = dates[:test_set_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data open, we can go ahead and do any preprocessing needed for it to run in our models. If teams reshaped or adjusted their model's data in any way this code should be changed to reflect those adjustments\n",
    "\n",
    "The code below handles some of the basic data handling we did in the model training tutorial. We'll need to use this formatted data for our model to accept it as input. The bottom code snippet does just that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_dates = []\n",
    "\n",
    "for date_string in test_dates:\n",
    "    formatted_date = datetime.strptime(date_string.decode(), '%Y%m%d%H%M')\n",
    "\n",
    "    year = formatted_date.year\n",
    "    month = formatted_date.month\n",
    "    day = formatted_date.day\n",
    "    hour = formatted_date.hour\n",
    "    minute = formatted_date.minute\n",
    "\n",
    "    formatted_dates.append(np.array([year, month, day, hour, minute]))\n",
    "\n",
    "test_dates = np.array(formatted_dates).reshape(test_set_size, 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll define our model architecture. This is necessary in order to load the previously trained model. If you have any questions on how we obtained the *lstm_model.h5* file please review the previous LSTM model training tutorial where we covered this in more depth\n",
    "\n",
    "Teams should replace the bottom code snippet to load their custom built models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='tanh', input_shape=(5, 1)))\n",
    "model.add(Dense(2 * 16 * 8, activation='linear'))\n",
    "model.add(Reshape((2, 16, 8)))\n",
    "\n",
    "model = load_model('lstm_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model's correctly loaded in, we can simply evaluate it's performance on our \"test set\". Examining it's RMSE we can get a quick idea how the model performed on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 6ms/step - loss: 50.9386\n",
      "Root Mean Squared Error: 7.137125238577685\n"
     ]
    }
   ],
   "source": [
    "mse = model.evaluate(test_dates, test_traffic_data)\n",
    "\n",
    "# Show rmse to see how model performs on the test set\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see our model's achieved RMSE, it's important for teams to remember that model performance will not be the sole judging criteria for this competition. Team presentations will also play a large role in determining overall placing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes this sample notebook. Teams are encouraged to send in their testing notebooks by Friday, February 2nd by 5pm EST\n",
    "\n",
    "If any teams have follow up questions or need any help relating to this notebook, please feel free to drop a question in the hackathon teams chat. We are all more than happy to help answer any questions you might have!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Thank you and best of luck!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
